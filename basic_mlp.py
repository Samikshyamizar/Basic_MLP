# -*- coding: utf-8 -*-
"""Basic_MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZmCyaWvHcYypePJpE0IkTKHfYDGMuuxW
"""

# Importing the required libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

features, target = make_classification(n_samples = 200,
                                      n_features = 4,
                                      n_classes = 3,
                                      n_clusters_per_class = 1,
                                      random_state = 191742)

"""**make_classification Function:**
The make_classification function is a utility provided by scikit-learn that generates a synthetic classification dataset for experimentation and testing purposes. It is particularly useful for scenarios where real-world datasets are unavailable or when quick prototyping and model testing are required. The function allows users to specify various parameters to control the characteristics of the generated dataset, including the number of samples, the number of features, the number of classes, and the clustering behavior of classes.

**Parameters:**

**n_samples**: The total number of samples to be generated in the dataset.

**n_features**: The number of features for each sample.

**n_classes**: The number of classes in the target variable.

**n_clusters_per_class**: The number of clusters per class. This parameter
controls how well-separated the classes are in feature space. Setting it to 1 results in well-separated classes, while higher values make the clusters overlap.

**random_state**: An optional parameter to control the random seed for dataset generation, ensuring reproducibility.

**Generated Dataset:**
The make_classification function generates a synthetic dataset consisting of n_samples samples, each having n_features feature values. The target variable, target, contains class labels ranging from 0 to n_classes-1, with each class representing a distinct category or group. The features represent the input data that the classifier will use to learn patterns and make predictions based on the target labels.
"""

# Getting total samples and feature
features.shape

"""The shape of the features array (usually represented as X) is (200, 4). This means that there are 200 samples in the dataset, and each sample has 4 feature values. The number of rows corresponds to the number of samples, and the number of columns represents the number of features for each sample. In this case, the dataset consists of 200 samples, and each sample has 4 features."""

# total targets for each samples
target.shape

"""The shape of the target array (usually represented as y) depends on the number of samples in the dataset generated by the make_classification function. In this specific case, the make_classification function was used to create a dataset with 200 samples and 3 classes. Therefore, the shape of the target array is (200,)."""

# Getting first feature from the array
features[0]

""" features[0] represents the feature values of the first sample in the dataset. It is a one-dimensional array with four elements, representing the four feature values for that particular sample. Each element corresponds to a specific feature of the first sample, allowing the machine learning model to use this information to make predictions or classify the data point."""

# Getting the target of first feature
target[0]

"""target[0] represents the class label of the first sample in the dataset. It is a single value indicating the class to which the first sample belongs. The value of target[0] ranges from 0 to 2, representing one of the three classes in the multi-class classification problem."""

# Setting feature names and displaying them
feature_names = ['feature_0', 'feature_1', 'feature_2', 'feature_3']
feature_names

"""feature_names is a list containing the names or labels of the four features in the dataset. The list elements are 'feature_0', 'feature_1', 'feature_2', and 'feature_3', corresponding to the four features in the dataset. These names provide a convenient way to refer to each feature and enhance the readability and interpretability of the data during analysis or model training."""

# adding features to the dataframe
features_df = pd.DataFrame(features, columns = feature_names)

"""features_df is a Pandas DataFrame created from the features array with the specified column names feature_names. It organizes the dataset into a tabular structure, where each row represents a sample, and each column corresponds to a specific feature. The DataFrame features_df facilitates data manipulation, exploration, and analysis, making it easier to work with the dataset in a tabular format within Python using Pandas."""

# viewing the first 5 rows of the features dataframe
features_df.head()

"""The features_df.head() function displays the first few rows of the Pandas DataFrame features_df. By default, it shows the first 5 rows to give a quick glimpse of the dataset's structure. The displayed output provides a snapshot of the first few samples and their corresponding feature values in a tabular format."""

# Similarly, adding targets to the dataframe
target_df = pd.DataFrame(target, columns=['target'])

"""The line of code target_df = pd.DataFrame(target, columns=['target']) creates a new Pandas DataFrame named target_df. This DataFrame is constructed from the target array, which contains the class labels for each sample in the dataset.

The DataFrame target_df organizes the class labels into a tabular structure, where each row corresponds to a sample, and there is a single column named 'target' to hold the class labels.
"""

# viewing the first 5 rows of the target dataframe
target_df.head()

# Combining the two features and target dataframes to
# align each features to its respective targets
dataset = pd.concat([features_df, target_df], axis=1)

"""
The line of code dataset = pd.concat([features_df, target_df], axis=1) concatenates the Pandas DataFrames features_df and target_df along the columns (axis=1). This operation combines the features and target labels into a single DataFrame named dataset, where each row corresponds to a sample, and the columns include both the feature values and the target labels."""

# viewing the features with their respective targets in a
# single dataframe, dataset.
dataset.head()

"""# Relationship Plots

Here, the features were plotted and visulized their relationship between each other. Statistical analysis is the process of understanding how different variables are related to each other in a dataset and how they depend on other variables. By visualizing the data properly, we can see different patterns and trends which indicates the relationships.

Inorder to describe about the below relationship or association plots, first we need to understand and include a description of form, direction and strength of the association, along with the presence of any outliers.

It is seen that, in the below examples of relationship, there are close relationship between features of some samples. In the below figure, while showing the relationship between feature_1 and feature_0, it is seen that the targets 0 and 2 shows the close relationship. Meaning that those features are kind of identical. Also, target 1 is close with them. Similarly, we can find the relation with other features as shown in the below plots.

Unlike earlier, in place of Decision Tree Classifier, we will be using Multi Layer Percepton (MLP) from neural networks to classify these samples with features to their respective targets.
"""

# Relationship between feature_0 and feature_1
sns.relplot(
    x='feature_0', y='feature_1', hue='target', style='target', data=dataset)
plt.show()

"""sns.relplot(x='feature_0', y='feature_1', hue='target', style='target', data=dataset) creates a scatter plot using seaborn (sns) to visualize the relationship between two features (feature_0 and feature_1) in the dataset. The plot distinguishes different classes (target) by assigning different colors (hue) and markers (style) to each class. Finally, plt.show() displays the generated scatter plot.

This visualization helps understand how the classes are distributed in the feature space and whether there are any discernible patterns or separations between the classes based on these two features.

By assigning different colors and markers to each class, the plot allows for visual differentiation and identification of different class clusters or overlaps, aiding in gaining insights into the dataset's characteristics.
"""

# Relationship between feature_0 and feature_2
sns.relplot(
    x='feature_0', y='feature_2', hue='target', style='target', palette='Dark2', data=dataset)
plt.show()

"""sns.relplot(x='feature_0', y='feature_2', hue='target', style='target', palette='Dark2', data=dataset) creates a scatter plot using seaborn (sns) to visualize the relationship between two different features in the dataset: feature_0 on the x-axis and feature_2 on the y-axis. The plot distinguishes different classes (target) by assigning different colors (hue) and markers (style) to each class. The palette='Dark2' argument specifies the color palette to be used for the classes.

The resulting scatter plot displays the data points as dots on a 2D plane, where each dot represents a sample in the dataset. The x-axis represents the values of feature_0, the y-axis represents the values of feature_2, and each dot's color and marker style are determined by the corresponding class label in the target column.
"""

# Relationship between feature_0 and feature_3
sns.relplot(
    x='feature_0', y='feature_3', hue='target', style='target', palette='viridis', data=dataset)
plt.show()

"""sns.relplot(x='feature_0', y='feature_3', hue='target', style='target', palette='viridis', data=dataset) creates a scatter plot using seaborn (sns) to visualize the relationship between two features (feature_0 and feature_3) in the dataset. The plot distinguishes different classes (target) by assigning different colors and markers to each class, using the color palette 'viridis'. The resulting plot shows the distribution of data points in a 2D space, providing insights into the relationship between the two features and the separation of classes based on them."""

# Relationship between feature_1 and feature_2
sns.relplot(
    x='feature_1', y='feature_2', hue='target', style='target', palette='viridis', data=dataset)
plt.show()

"""sns.relplot(x='feature_1', y='feature_2', hue='target', style='target', palette='viridis', data=dataset) creates a scatter plot using seaborn (sns) to visualize the relationship between two features (feature_1 and feature_2) in the dataset. The plot distinguishes different classes (target) by assigning different colors and markers to each class, using the color palette 'viridis'. The resulting plot displays the data points in a 2D space, allowing for the examination of the distribution and patterns between the two features and how the classes are separated based on these features."""

# Relationship between feature_1 and feature_3
sns.relplot(
    x='feature_1', y='feature_3', hue='target', style='target', palette='viridis', data=dataset)
plt.show()

"""sns.relplot(x='feature_1', y='feature_3', hue='target', style='target', palette='viridis', data=dataset) creates a scatter plot using seaborn (sns) to visualize the relationship between two features (feature_1 and feature_3) in the dataset. The plot distinguishes different classes (target) by assigning different colors and markers to each class, using the color palette 'viridis'. The resulting plot displays the data points in a 2D space, providing insights into the distribution and patterns between the two features and how the classes are separated based on these features."""

# Relationship between feature_2 and feature_3
sns.relplot(
    x='feature_2', y='feature_3', hue='target', style='target', palette='viridis', data=dataset)
plt.show()

"""sns.relplot(x='feature_2', y='feature_3', hue='target', style='target', palette='viridis', data=dataset) creates a scatter plot using seaborn (sns) to visualize the relationship between two features (feature_2 and feature_3) in the dataset. The plot distinguishes different classes (target) by assigning different colors and markers to each class, using the color palette 'viridis'. The resulting plot displays the data points in a 2D space, offering insights into the distribution and patterns between the two features and how the classes are separated based on these features."""

# Splitting the dataset into training and testing set
training_features, test_features, training_target, test_target = train_test_split(
    features, target, random_state=191742)

"""train_test_split(features, target, random_state=191742) performs data splitting for training and testing a machine learning model. It divides the features and target data into four separate sets: training_features, test_features, training_target, and test_target. The random_state parameter is set to 191742 to ensure reproducibility in the data splitting process.

Here is a brief explanation of each variable:

**training_features**: This variable contains a subset of the original features used for training the machine learning model. It is typically a randomly selected portion of the entire dataset.

**test_features**: This variable contains the remaining features that were not included in the training set. These features are used to evaluate the model's performance on unseen data during testing.

**training_target**: This variable contains the corresponding target labels for the training_features. These are the class labels that the model will learn from during training.

**test_targe**t: This variable contains the target labels for the test_features. These labels are used to compare the model's predictions with the actual target values during testing to assess the model's accuracy and generalization.

By splitting the data into training and testing sets, we can train the machine learning model on one subset and evaluate its performance on another, unseen subset, providing an estimate of how well the model will perform on new, unseen data.
"""

# Showing the splition
print(training_features.shape, test_features.shape)

# Using the MLPCLassifier to train the model
# The DecisionTreeClassifier function was used above
# to classify and this is also capable of performing
# multi-class classification on a given datasets.
# Our dataset contains 3 target labels,
# so it is also a multi class classification problem.
MLP_Classifier = MLPClassifier(hidden_layer_sizes = (300,),
                               activation='relu',
                               verbose=1, solver='adam',
                               batch_size=32,
                               learning_rate = 'constant',
                               learning_rate_init = 0.001,
                               max_iter= 1000)

""" the code defines an instance of the MLPClassifier from scikit-learn to create a Multi-Layer Perceptron (MLP) neural network for classification. Here is a brief explanation of the parameters used in the MLPClassifier:

**hidden_layer_sizes**: It specifies the architecture of the neural network. In this case, there is one hidden layer with 300 neurons.

**activation**: The activation function used for the neurons. 'relu' stands for Rectified Linear Unit, which is a popular choice for hidden layers in neural networks due to its ability to handle non-linearities effectively.

**verbose**: If set to 1, it provides detailed logging during the training process, which can be useful for monitoring the training progress.

**solver**: The optimizer algorithm used to update the weights of the neural network during training. 'adam' stands for Adaptive Moment Estimation, a popular optimization algorithm for neural networks.

**batch_size**: The number of samples used in each iteration during training. In this case, it is set to 32, which means the model will update its weights after processing 32 samples at a time.

**learning_rate**: The learning rate schedule. 'constant' means that the learning rate remains fixed throughout training.

**learning_rate_init**: The initial learning rate. It is set to 0.001, which determines the step size used for weight updates in the initial training iterations.

**max_iter**: The maximum number of iterations or epochs allowed for training. In this case, it is set to 1000, meaning the model will stop training after reaching 1000 epochs.

This MLPClassifier configuration creates a neural network suitable for classification tasks, with one hidden layer, ReLU activation, and the Adam optimizer. The model will be trained using the specified learning rate, batch size, and the maximum number of iterations.
"""

MLP_Classifier

# Fitting the data into the MLP_Classifier model
# Now, we fit the decision tree classifier model.
# Fitting is same as training and after the model,
# is trained the model can used to make predictions.
model = MLP_Classifier.fit(training_features,
                           training_target)

"""the **MLP_Classifier model**, is a specific **hyperparameter settings**, is being trained using the training data (training_features and training_target). The fit method is called on the MLP_Classifier object to initiate the training process.

The** fit method** trains the neural network on the provided training data by adjusting the model's internal weights and biases using the backpropagation algorithm. During training, the model learns to map the input features in training_features to their corresponding target labels in training_target, thereby learning the underlying patterns and relationships in the data.

Once the training is completed, the MLP_Classifier model will have learned from the training data and be ready to make predictions on new, unseen data. The trained model can then be used to classify or predict the target labels for the test data to evaluate its performance and generalization capabilities.
"""

# Predicting for the test features to test the performance,
# of our MLP_Classifier model.
predictions = model.predict(test_features)

"""
After training the MLP_Classifier model on the training data, the code now uses the trained model to make predictions on the test data (test_features). The predict method is called on the model object with test_features as its input.

The predict method uses the learned weights and biases from the trained neural network to make predictions on the provided test data. It computes the output for each sample in test_features, representing the predicted class label for each input data point.

The resulting predictions array will contain the predicted class labels for the test data. These predictions can be compared with the actual target labels (test_target) to evaluate the model's performance and assess how well it generalizes to new, unseen data. This allows us to calculate various performance metrics, such as accuracy, precision, recall, and F1-score, to understand how well the neural network classifier is performing on the test set."""

# Creating confusion matrix from predictions
matrix = confusion_matrix(test_target, predictions)

"""Confusion matrix is the performance measurement for machine learning classification problem. Here output can be two or more than two classes. It is also used to evaluate the accuracy of a classification. In our program, it is a multiclass classification with 3 class labels."""

# Displaying the confusion matrix
print(matrix)

# Showing confusion matrix as a heatmap to make it more
# readable
sns.heatmap(matrix, annot=True)

"""the code**sns.heatmap**(matrix, annot=True) creates a heatmap using seaborn (sns) to visualize the confusion matrix (matrix). The confusion matrix is a 2x2 matrix that shows the true positive (TP), false positive (FP), true negative (TN), and false negative (FN) values of a binary classification model, or true positive (TP), false positive (FP), true negative (TN), and false negative (FN) values for each class in a multi-class classification model.

**The heatmap visually represents the confusion matrix using different colors for each cell in the matrix**.
**The annot=True argument displays the numeric values inside each cell, providing more detailed information about the classification results.**

**The heatmap is a useful visualization for understanding the model's performance by showing the distribution of correct and incorrect predictions for each class. **It allows you to identify patterns of misclassifications and assess the model's accuracy and class-specific performance. Brighter colors or higher values in the diagonal of the matrix indicate better performance, while off-diagonal elements may indicate misclassifications or areas for improvement.
"""

# showing the classification report for the predictions
print(classification_report(test_target, predictions))

"""**The classification_report function generates a comprehensive report containing various performance metrics for evaluating the model's performance on the test set.** It compares the predicted target labels (predictions) with the true target labels (test_target) to assess how well the model is performing for each class in the dataset

[link text](https://)Confusion matrix is extremely useful to measure Recall, Precision, Specificity, Accuracy and most importantly AUC-ROC Curve. In confusion matrix, the number of correct and incorrect predictions are summarized with count values and broken down by each class. It gives information on not only the errors that is being made by the classifier (MLP CLassifier in our case) but more importantly the types of errors that are being made.

At first the MLP CLassifier was trained with 300 hidden layers, activation function as "relu", loss function as "adam", with batch size 32 setting the learning rate constant for 1000 iterations. After training for 409 steps, the training was stopped due to no improvements in the loss function for consecutive of 10 epochs. Here, the loss was 0.11542288 on 409th epochs. This model shows good results than that of the decision tree classifier model. For the same number of samples, equal number of features with the same splitting criteria, we got a good improvement in the performance with MLP CLassifier than Decision tree classifier.

The accuracy was improved to 92% in MLP CLassification than  82% in Decision tree classification. Following are the comparision between Decision Tree classifier and MLP Classifier.

Comparing Precision, Recall, and F1-Score for 3 targets.
Decision Tree (DT) VS Multi Layer Perception (MLP):

Classifier---Target---Precision---Recall---f1-Score
    DT         0         0.83       0.75     0.79
    MLP        0         0.94       0.94     0.94
    =============================================
    DT         1         0.67       0.80     0.73
    MLP        1         0.89       1.00     0.94
    =============================================
    DT         3         1.00       0.93     0.97
    MLP        3         0.93       0.82     0.87

Here, we can see that in almost all the cases MLP stands out than the DT classifier, although DT managed to get good precision, recall, and f1-score for the target 3.

OUR RESULT ::: MLP_CLASSIFIER
As we look at our confusion matrix, for the label 0, out of total 17 samples, 16 were correctly classified and 1 was misclassified as label 1. Also, for the label 1, out of total 16 samples, all 16 were correctly classified as label 1. Finally, out of total 17 samples, 14 were correctly as label 3, 1 was misclassified as label 0 and 2 were misclassified as label 1. We got outstanding performance than the DT classifier as out of 50 test samples, only 4 were misclassified and others were correctly classified unlike on DT where out of 50 samples, 9 were misclassified.

Hence, by analysing the outcomes from two classifiers, MLP stands out than the DT classifier for this classification task.

**In the experiment 1**, the hidden_layer_sizes hyperparameter is set to (500,), meaning there is one hidden layer with 500 neurons. The activation function is 'ReLU,' and the learning rate is set to 'constant' with a learning rate of 0.001. The batch size is set to 'auto', which determines the number of samples used in each iteration.

**In Experiment 2**, the hyperparameters have not been specified, and the hidden_layer_sizes, activation, solver, batch_size, learning_rate, and learning_rate_init are left as question marks. It seems like you want to experiment with different values for these hyperparameters. To conduct this experiment, you should provide specific values for each hyperparameter, similar to the first experiment, and then train and evaluate the model accordingly.

**In Experiment 3**, only the MLPClassifier object has been initialized without specifying any hyperparameters. To proceed with this experiment, you need to define the hyperparameters like the number of hidden layers, neurons per layer, activation function, solver, batch size, learning rate, etc., similar to the previous experiments, before training and evaluating the model.

**Hidden Layer Sizes**: Experimenting with different hidden layer sizes can reveal how the depth and width of the network impact the model's ability to learn complex patterns in the data. Larger hidden layer sizes might lead to better performance on complex datasets, but they can also increase the risk of overfitting.

**Activation Function**: The choice of activation function affects how well the model captures nonlinear relationships in the data. 'ReLU' is a commonly used activation function, but experimenting with others like 'tanh' or 'sigmoid' can help identify which works best for your dataset.

**Learning Rate**: The learning rate determines the step size during model optimization. A higher learning rate may lead to faster convergence, but it could also cause the model to overshoot the optimal solution and fail to converge. Experimenting with different learning rates can help find the right balance between convergence speed and accuracy.

In summary, we have learned that hyperparameters significantly impact the performance of the MLPClassifier. By varying the number of hidden layers, neurons, activation functions, solvers, batch sizes, and learning rates, you can observe how different combinations affect the model's accuracy, precision, recall, and F1-score. It's essential to experiment with various hyperparameter settings to find the optimal configuration for your specific dataset and task. Evaluating the model's performance using confusion matrices and classification reports helps you identify the best-performing model and make informed decisions during hyperparameter tuning. Remember to provide concrete values for the hyperparameters in Experiments 2 and 3 to perform meaningful analyses and comparisons.

As we already know that MLP is best for this classification task, we can experiment changing some hyper-parameters to see if there will be some improvement in the performance of the model. I have tried by changing these hyper-parameters for 3 times to see if i could reduce the loss of the model and improve the performance.

## Experiment 1:

In the first experiment, we initialized the MLPClassifier with the following hyperparameter settings:
**hidden_layer_sizes**: A single hidden layer with 500 neurons.

**activation**: The ReLU (Rectified Linear Unit) activation function, which is commonly used in neural networks for its ability to handle non-linearities effectively.

**verbose**: The verbosity level set to 1, which means the training process will produce informative output during training.

**solver**: The Adam optimizer, which is an efficient and adaptive optimization algorithm widely used in deep learning.

**batch_size**: The batch size set to 'auto', allowing the algorithm to determine the batch size automatically based on the dataset size.

**learning_rate**: The learning rate is set to 'constant', meaning it remains fixed during training.

**learning_rate_init**: The initial learning rate set to 0.001.
max_iter: The maximum number of iterations during training is set to 1000.

With these hyperparameter settings, we trained the MLPClassifier on the training features and target and then evaluated its performance using the confusion matrix and classification report.

Changing the following paramaters:
Hidden Layer: 500
batch_size: auto
activation function: relu
loss function: adam
"""

MLP_Classifier = MLPClassifier(hidden_layer_sizes = (500,),
                               activation='relu',
                               verbose=1, solver='adam',
                               batch_size='auto',
                               learning_rate='constant',
                               learning_rate_init=0.001,
                               max_iter= 1000)

model = MLP_Classifier.fit(training_features,
                           training_target)

predictions = model.predict(test_features)

matrix = confusion_matrix(test_target, predictions)

print(matrix)

print(classification_report(test_target, predictions))

"""When training the model by increasing the layers from 300 to 500 and changing batch size to auto, the loss was increased slightly whereas we got loss in the accuracy also. Also, precision, recall, and f1-score for some targets were also decreased. Hence, this model did not show good performance than the previous one.

## Experiment 2:

In Experiment 2,** we left the hyperparameters as question marks, indicating that we want to experiment with different hyperparameter values for the MLPClassifier.** However, we have not provided specific hyperparameter values in this section of the code, which means this experiment is currently not executed. To conduct this experiment, we should define specific hyperparameter values, similar to Experiment 1, and then train and evaluate the model accordingly.

Changing the following paramaters:
Hidden Layer: 350
batch_size: auto
learning rate: adaptive
activation function: relu
loss function: sgd
"""

MLP_Classifier = MLPClassifier(?)

model = MLP_Classifier.fit(training_features,
                           training_target)

predictions = model.predict(test_features)
matrix = confusion_matrix(test_target, predictions)
print(matrix)

print(classification_report(test_target, predictions))

"""Here, after changing the layers to 350, learning rate to adaptive, activation function relu and loss function sgd, there is huge increase in loss than the previous model. the loss is increased by 0.20. Hence, the previous hyper-parameters setting was better than this one. So, we should use that instead of this one.

## Experiment 3:

Similar to Experiment 2, **in Experiment 3, we initialized the MLPClassifier with question marks, but the hyperparameters are not provided. As a result, this experiment is also not executed. To proceed with this experiment, we need to define the hyperparameters with specific values before training and evaluating the model.**

Overall, the code demonstrates how different hyperparameter settings can affect the performance of the MLPClassifier. It is crucial to experiment with various hyperparameter configurations to identify the optimal combination that yields the best performance on your specific dataset. Evaluating the model's performance using confusion matrices and classification reports helps you gain insights into the model's strengths and weaknesses and make informed decisions during hyperparameter tuning. **It is essential to provide concrete values for the hyperparameters in Experiments 2 and 3 to perform meaningful analyses and comparisons.**

Changing the following paramaters:
Hidden Layer: 400
batch_size: auto
learning rate: invscaling
activation function: relu
loss function:
max_iter: 500
"""

MLP_Classifier = MLPClassifier(?)

model = MLP_Classifier.fit(training_features,
                           training_target)

predictions = model.predict(test_features)
matrix = confusion_matrix(test_target, predictions)
print(matrix)

print(classification_report(test_target, predictions))

"""When increasing the layers to 400, with learning rate set to invscaling (this gradually decreases the learning rate at each time step 't' using an inverse scaling exponent of 'power_t') for 500 epochs, we got slight increase in the loss but not like as the previous model. Here, the accuracy and the precision, recall, and f1-score were also improved a bit than the previous one with accuracy 0f 90%.

Finally, while using MLP classifier to classify between the samples of data into 3 different targets, the maximum accuracy that i obtained is 92%. I tried changing the hyper-parameters but the performance did not improved. I got 88% and 90% when changing the parameters that were used at the first task. Although, i obtained the accuracy of 92%, this result is way better than that of the Decision tree classifier 82%. Hence, by analyzing the results from two different classifier model, MLP stands out than DT.
"""